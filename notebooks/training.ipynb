{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional, Input, GlobalMaxPool1D, Activation\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../dataset_text/miditokens.txt'\n",
    "with open(filename) as f:\n",
    "    miditokens = f.readlines()\n",
    "    \n",
    "midiTokensWithMeta = [tokens.strip().split(' ') for tokens in miditokens]\n",
    "\n",
    "miditokens = []\n",
    "for i in range(len(midiTokensWithMeta)):\n",
    "    if 'timesig:4/4' in midiTokensWithMeta[i]:\n",
    "        midiInfo = midiTokensWithMeta[i]\n",
    "        \n",
    "        if midiInfo[1].startswith('tempo'):\n",
    "            midiInfo.remove(midiInfo[1])\n",
    "        \n",
    "        midiInfo.remove('timesig:4/4')\n",
    "        \n",
    "        miditokens.append(midiTokensWithMeta[i])\n",
    "miditokens = miditokens[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer() # token -> int\n",
    "tokenizer.fit_on_texts(miditokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249\n"
     ]
    }
   ],
   "source": [
    "#sample = miditokens[1]\n",
    "#print(sample)\n",
    "#print(tokenizer.texts_to_sequences([sample])[0]) # Example of token input -> int output\n",
    "#print(\"Sõna sagedus kogu andmestikus\", tokenizer.word_counts['end'])\n",
    "#print(\"Sõna -> indeks teisendus\", tokenizer.word_index['note:c4:v112'])\n",
    "#print(\"Indeks -> sõna teisendus\", tokenizer.index_word[55])\n",
    "print(len(tokenizer.word_index))\n",
    "#print(tokenizer.index_word)\n",
    "#print(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn all tokens to ints\n",
    "midiTokensAsInt = tokenizer.texts_to_sequences(miditokens)\n",
    "#midiTokensAsInt = np.array(midiTokensAsInt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://medium.com/analytics-vidhya/train-keras-model-with-large-dataset-batch-training-6b3099fdf366\n",
    "#\n",
    "#def batchGenerator(trainData, VOCAB_SIZE, SEQ_LEN=30):\n",
    "#    i = 0\n",
    "#    while True:\n",
    "#        yield loadDataBatch(trainData, VOCAB_SIZE, SEQ_LEN, i)\n",
    "#        i += 1\n",
    "#    \n",
    "#            \n",
    "#def loadDataBatch(trainData, VOCAB_SIZE, SEQ_LEN, i):\n",
    "#    X = []\n",
    "#    y = []\n",
    "#    \n",
    "#    # https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5\n",
    "#    \n",
    "#    song = trainData[i]\n",
    "#    for i in range(0, len(song) - SEQ_LEN, 1):\n",
    "#        X.append(song[i:i + SEQ_LEN])\n",
    "#        y.append(song[i + SEQ_LEN])\n",
    "#            \n",
    "#    input_len = len(X)\n",
    "#    \n",
    "#    # reshape the input into a format compatible with LSTM layers\n",
    "#    X = np.reshape(X, (input_len, SEQ_LEN, 1))\n",
    "#    \n",
    "#    # normalize input\n",
    "#    X = X / float(VOCAB_SIZE)\n",
    "#    y = to_categorical(y, num_classes = VOCAB_SIZE)\n",
    "#    \n",
    "#    return (X, y)\n",
    "#\n",
    "#VOCAB_SIZE = len(tokenizer.word_index)\n",
    "#SEQ_LEN = 20\n",
    "#\n",
    "#batchGen = batchGenerator(midiTokensAsInt, VOCAB_SIZE, SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Sequential()\n",
    "#model.add(LSTM(\n",
    "#    256,\n",
    "#    input_shape=(20, 1),\n",
    "#    return_sequences=True\n",
    "#))\n",
    "#model.add(Dropout(0.3))\n",
    "#model.add(LSTM(256, return_sequences=True))\n",
    "#model.add(Dropout(0.3))\n",
    "#model.add(LSTM(256))\n",
    "#model.add(Dense(256))\n",
    "#model.add(Dropout(0.3))\n",
    "#model.add(Dense(VOCAB_SIZE))\n",
    "#model.add(Activation('softmax'))\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "#\n",
    "#filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"    \n",
    "#checkpoint = ModelCheckpoint(\n",
    "#    filepath, monitor='loss', \n",
    "#    verbose=0,        \n",
    "#    save_best_only=True,        \n",
    "#    mode='min'\n",
    "#)    \n",
    "#callbacks_list = [checkpoint]     \n",
    "##model.fit(network_input, network_output, epochs=200, batch_size=64, callbacks=callbacks_list)\n",
    "#\n",
    "#model.fit(batchGen, \n",
    "#          epochs=200,\n",
    "#          callbacks=callbacks_list,\n",
    "#          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-generator variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "VOCAB_SIZE = len(tokenizer.word_index)\n",
    "SEQ_LEN = 100\n",
    "\n",
    "# https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5\n",
    "\n",
    "for song in midiTokensAsInt:\n",
    "    for i in range(0, len(song) - SEQ_LEN, 1):\n",
    "        X.append(song[i:i + SEQ_LEN])\n",
    "        y.append(song[i + SEQ_LEN])\n",
    "\n",
    "X_train = X\n",
    "y_train = y\n",
    "\n",
    "input_len = len(X_train)\n",
    "\n",
    "# reshape the input into a format compatible with LSTM layers\n",
    "X_train = np.reshape(X_train, (input_len, SEQ_LEN, 1))\n",
    "\n",
    "# normalize input\n",
    "X_train = X_train / float(VOCAB_SIZE)\n",
    "\n",
    "y_train = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1898/1898 [==============================] - 131s 66ms/step - loss: 4.5352\n",
      "Epoch 2/200\n",
      "1898/1898 [==============================] - 124s 65ms/step - loss: 3.9878\n",
      "Epoch 3/200\n",
      "1898/1898 [==============================] - 124s 65ms/step - loss: 3.5446\n",
      "Epoch 4/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 3.1954\n",
      "Epoch 5/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 2.9275\n",
      "Epoch 6/200\n",
      "1898/1898 [==============================] - 124s 65ms/step - loss: 2.7369\n",
      "Epoch 7/200\n",
      "1898/1898 [==============================] - 124s 65ms/step - loss: 2.5856\n",
      "Epoch 8/200\n",
      "1898/1898 [==============================] - 124s 65ms/step - loss: 2.4574\n",
      "Epoch 9/200\n",
      "1898/1898 [==============================] - 124s 65ms/step - loss: 2.3474\n",
      "Epoch 10/200\n",
      "1898/1898 [==============================] - 124s 65ms/step - loss: 2.2555\n",
      "Epoch 11/200\n",
      "1898/1898 [==============================] - 124s 65ms/step - loss: 2.1837\n",
      "Epoch 12/200\n",
      "1898/1898 [==============================] - 124s 66ms/step - loss: 2.1047\n",
      "Epoch 13/200\n",
      "1898/1898 [==============================] - 122s 64ms/step - loss: 2.0520\n",
      "Epoch 14/200\n",
      "1898/1898 [==============================] - 121s 64ms/step - loss: 1.9993\n",
      "Epoch 15/200\n",
      "1898/1898 [==============================] - 121s 64ms/step - loss: 1.9429\n",
      "Epoch 16/200\n",
      "1898/1898 [==============================] - 121s 64ms/step - loss: 1.9030\n",
      "Epoch 17/200\n",
      "1898/1898 [==============================] - 121s 64ms/step - loss: 1.8583\n",
      "Epoch 18/200\n",
      "1898/1898 [==============================] - 121s 64ms/step - loss: 1.8328\n",
      "Epoch 19/200\n",
      "1898/1898 [==============================] - 121s 64ms/step - loss: 1.7984\n",
      "Epoch 20/200\n",
      "1898/1898 [==============================] - 121s 64ms/step - loss: 1.7668\n",
      "Epoch 21/200\n",
      "1898/1898 [==============================] - 121s 64ms/step - loss: 1.7378\n",
      "Epoch 22/200\n",
      "1898/1898 [==============================] - 121s 64ms/step - loss: 1.7051\n",
      "Epoch 23/200\n",
      "1898/1898 [==============================] - 121s 64ms/step - loss: 1.6768\n",
      "Epoch 24/200\n",
      "1898/1898 [==============================] - 121s 64ms/step - loss: 1.6663\n",
      "Epoch 25/200\n",
      "1898/1898 [==============================] - 121s 64ms/step - loss: 1.6411\n",
      "Epoch 26/200\n",
      "1898/1898 [==============================] - ETA: 0s - loss: 1.620 - 121s 64ms/step - loss: 1.6201\n",
      "Epoch 27/200\n",
      "1898/1898 [==============================] - 121s 64ms/step - loss: 1.5980\n",
      "Epoch 28/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.5708\n",
      "Epoch 29/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.5610\n",
      "Epoch 30/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.5460\n",
      "Epoch 31/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.5290\n",
      "Epoch 32/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.5296\n",
      "Epoch 33/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.5096\n",
      "Epoch 34/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.4890\n",
      "Epoch 35/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.4777\n",
      "Epoch 36/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.4676\n",
      "Epoch 37/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.4616\n",
      "Epoch 38/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.4440\n",
      "Epoch 39/200\n",
      "1898/1898 [==============================] - 126s 66ms/step - loss: 1.4363\n",
      "Epoch 40/200\n",
      "1898/1898 [==============================] - 122s 64ms/step - loss: 1.4217\n",
      "Epoch 41/200\n",
      "1898/1898 [==============================] - 121s 64ms/step - loss: 1.4131\n",
      "Epoch 42/200\n",
      "1898/1898 [==============================] - 121s 64ms/step - loss: 1.4057\n",
      "Epoch 43/200\n",
      "1898/1898 [==============================] - 121s 64ms/step - loss: 1.3926\n",
      "Epoch 44/200\n",
      "1898/1898 [==============================] - 121s 64ms/step - loss: 1.3794\n",
      "Epoch 45/200\n",
      "1898/1898 [==============================] - 121s 64ms/step - loss: 1.3753\n",
      "Epoch 46/200\n",
      "1898/1898 [==============================] - 122s 64ms/step - loss: 1.3670\n",
      "Epoch 47/200\n",
      "1898/1898 [==============================] - 124s 66ms/step - loss: 1.3575\n",
      "Epoch 48/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.3458\n",
      "Epoch 49/200\n",
      "1898/1898 [==============================] - 126s 66ms/step - loss: 1.3471\n",
      "Epoch 50/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.3333\n",
      "Epoch 51/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.3232\n",
      "Epoch 52/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.3172\n",
      "Epoch 53/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.3126\n",
      "Epoch 54/200\n",
      "1898/1898 [==============================] - 129s 68ms/step - loss: 1.3061\n",
      "Epoch 55/200\n",
      "1898/1898 [==============================] - 124s 65ms/step - loss: 1.3000\n",
      "Epoch 56/200\n",
      "1898/1898 [==============================] - 124s 66ms/step - loss: 1.2928\n",
      "Epoch 57/200\n",
      "1898/1898 [==============================] - 124s 66ms/step - loss: 1.2875\n",
      "Epoch 58/200\n",
      "1898/1898 [==============================] - 124s 66ms/step - loss: 1.2781\n",
      "Epoch 59/200\n",
      "1898/1898 [==============================] - 124s 66ms/step - loss: 1.2746\n",
      "Epoch 60/200\n",
      "1898/1898 [==============================] - 124s 66ms/step - loss: 1.2653\n",
      "Epoch 61/200\n",
      "1898/1898 [==============================] - 124s 65ms/step - loss: 1.2568\n",
      "Epoch 62/200\n",
      "1898/1898 [==============================] - 121s 64ms/step - loss: 1.2553\n",
      "Epoch 63/200\n",
      "1898/1898 [==============================] - 121s 64ms/step - loss: 1.2455\n",
      "Epoch 64/200\n",
      "1898/1898 [==============================] - 121s 64ms/step - loss: 1.2408\n",
      "Epoch 65/200\n",
      "1898/1898 [==============================] - 122s 64ms/step - loss: 1.2342\n",
      "Epoch 66/200\n",
      "1898/1898 [==============================] - 122s 64ms/step - loss: 1.2378\n",
      "Epoch 67/200\n",
      "1898/1898 [==============================] - 122s 64ms/step - loss: 1.2278\n",
      "Epoch 68/200\n",
      "1898/1898 [==============================] - 122s 64ms/step - loss: 1.2235\n",
      "Epoch 69/200\n",
      "1898/1898 [==============================] - 122s 64ms/step - loss: 1.2151\n",
      "Epoch 70/200\n",
      "1898/1898 [==============================] - 124s 66ms/step - loss: 1.2135\n",
      "Epoch 71/200\n",
      "1898/1898 [==============================] - 124s 66ms/step - loss: 1.2119\n",
      "Epoch 72/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.2054\n",
      "Epoch 73/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.2112\n",
      "Epoch 74/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.1915\n",
      "Epoch 75/200\n",
      "1898/1898 [==============================] - 124s 66ms/step - loss: 1.1953\n",
      "Epoch 76/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.1852\n",
      "Epoch 77/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.1853\n",
      "Epoch 78/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.1819\n",
      "Epoch 79/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.1709\n",
      "Epoch 80/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.1677\n",
      "Epoch 81/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.1643\n",
      "Epoch 82/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.1658\n",
      "Epoch 83/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.1616\n",
      "Epoch 84/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.1466\n",
      "Epoch 85/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.1508\n",
      "Epoch 86/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.1484\n",
      "Epoch 87/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.1434\n",
      "Epoch 88/200\n",
      "1898/1898 [==============================] - 126s 66ms/step - loss: 1.1394\n",
      "Epoch 89/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.1319\n",
      "Epoch 90/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.1300\n",
      "Epoch 91/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.1269\n",
      "Epoch 92/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.1289\n",
      "Epoch 93/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1898/1898 [==============================] - 124s 65ms/step - loss: 1.1201\n",
      "Epoch 94/200\n",
      "1898/1898 [==============================] - 124s 66ms/step - loss: 1.1139\n",
      "Epoch 95/200\n",
      "1898/1898 [==============================] - 124s 66ms/step - loss: 1.1154\n",
      "Epoch 96/200\n",
      "1898/1898 [==============================] - 124s 66ms/step - loss: 1.1197\n",
      "Epoch 97/200\n",
      "1898/1898 [==============================] - 124s 66ms/step - loss: 1.1065\n",
      "Epoch 98/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.1006\n",
      "Epoch 99/200\n",
      "1898/1898 [==============================] - 124s 66ms/step - loss: 1.0961\n",
      "Epoch 100/200\n",
      "1898/1898 [==============================] - 124s 66ms/step - loss: 1.0985\n",
      "Epoch 101/200\n",
      "1898/1898 [==============================] - 124s 66ms/step - loss: 1.0919\n",
      "Epoch 102/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.0868\n",
      "Epoch 103/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.0869\n",
      "Epoch 104/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.0818\n",
      "Epoch 105/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.0821\n",
      "Epoch 106/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.0766\n",
      "Epoch 107/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.0788\n",
      "Epoch 108/200\n",
      "1898/1898 [==============================] - 124s 66ms/step - loss: 1.0715\n",
      "Epoch 109/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.0715\n",
      "Epoch 110/200\n",
      "1898/1898 [==============================] - 124s 66ms/step - loss: 1.0734\n",
      "Epoch 111/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.0653\n",
      "Epoch 112/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.0585\n",
      "Epoch 113/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.0624\n",
      "Epoch 114/200\n",
      "1898/1898 [==============================] - 123s 65ms/step - loss: 1.0548\n",
      "Epoch 115/200\n",
      "1898/1898 [==============================] - 121s 64ms/step - loss: 1.0514\n",
      "Epoch 116/200\n",
      "1898/1898 [==============================] - 121s 64ms/step - loss: 1.0468\n",
      "Epoch 117/200\n",
      "1898/1898 [==============================] - 121s 64ms/step - loss: 1.0461\n",
      "Epoch 118/200\n",
      "1898/1898 [==============================] - 121s 64ms/step - loss: 1.0461\n",
      "Epoch 119/200\n",
      "1898/1898 [==============================] - 121s 64ms/step - loss: 1.0436\n",
      "Epoch 120/200\n",
      "1898/1898 [==============================] - 121s 64ms/step - loss: 1.0382\n",
      "Epoch 121/200\n",
      "1898/1898 [==============================] - 121s 64ms/step - loss: 1.0365\n",
      "Epoch 122/200\n",
      "1898/1898 [==============================] - 121s 64ms/step - loss: 1.0428\n",
      "Epoch 123/200\n",
      "1898/1898 [==============================] - 121s 64ms/step - loss: 1.0331\n",
      "Epoch 124/200\n",
      "1898/1898 [==============================] - 121s 64ms/step - loss: 1.0403\n",
      "Epoch 125/200\n",
      "1898/1898 [==============================] - 121s 64ms/step - loss: 1.0342\n",
      "Epoch 126/200\n",
      "1898/1898 [==============================] - 121s 64ms/step - loss: 1.0266\n",
      "Epoch 127/200\n",
      "1898/1898 [==============================] - 121s 64ms/step - loss: 1.0197\n",
      "Epoch 128/200\n",
      "1898/1898 [==============================] - 121s 64ms/step - loss: 1.0182\n",
      "Epoch 129/200\n",
      "1898/1898 [==============================] - 121s 64ms/step - loss: 1.0270\n",
      "Epoch 130/200\n",
      "1898/1898 [==============================] - 121s 64ms/step - loss: 1.0122\n",
      "Epoch 131/200\n",
      "1898/1898 [==============================] - 124s 65ms/step - loss: 1.0187\n",
      "Epoch 132/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.0151\n",
      "Epoch 133/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.0187\n",
      "Epoch 134/200\n",
      "1898/1898 [==============================] - ETA: 0s - loss: 1.006 - 125s 66ms/step - loss: 1.0062\n",
      "Epoch 135/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.0131\n",
      "Epoch 136/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.0144\n",
      "Epoch 137/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 1.0034\n",
      "Epoch 138/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 0.9936\n",
      "Epoch 139/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 0.9939\n",
      "Epoch 140/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 0.9888\n",
      "Epoch 141/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 0.9918\n",
      "Epoch 142/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 0.9882\n",
      "Epoch 143/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 0.99050s - loss: 0.990\n",
      "Epoch 144/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 0.9923\n",
      "Epoch 145/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 0.9852\n",
      "Epoch 146/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 0.9795\n",
      "Epoch 147/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 0.9851\n",
      "Epoch 148/200\n",
      "1898/1898 [==============================] - 126s 66ms/step - loss: 0.9823\n",
      "Epoch 149/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 0.9755\n",
      "Epoch 150/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 0.9739\n",
      "Epoch 151/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 0.9729\n",
      "Epoch 152/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 0.9711\n",
      "Epoch 153/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 0.9651\n",
      "Epoch 154/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 0.9713\n",
      "Epoch 155/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 0.9673\n",
      "Epoch 156/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 0.9596\n",
      "Epoch 157/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 0.9665\n",
      "Epoch 158/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 0.9562\n",
      "Epoch 159/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 0.9567\n",
      "Epoch 160/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 0.9586\n",
      "Epoch 161/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 0.9534\n",
      "Epoch 162/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 0.9537\n",
      "Epoch 163/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 0.9551\n",
      "Epoch 164/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 0.9486\n",
      "Epoch 165/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 0.9475\n",
      "Epoch 166/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 0.9465\n",
      "Epoch 167/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 0.9478\n",
      "Epoch 168/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 0.9419\n",
      "Epoch 169/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 0.9483\n",
      "Epoch 170/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 0.9393\n",
      "Epoch 171/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 0.9354\n",
      "Epoch 172/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 0.9342\n",
      "Epoch 173/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 0.9326\n",
      "Epoch 174/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 0.9421\n",
      "Epoch 175/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 0.9460\n",
      "Epoch 176/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 0.9374\n",
      "Epoch 177/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 0.9372\n",
      "Epoch 178/200\n",
      "1898/1898 [==============================] - 125s 66ms/step - loss: 0.9322\n",
      "Epoch 179/200\n",
      "  37/1898 [..............................] - ETA: 2:04 - loss: 0.8690"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-434da5d5ad22>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m )    \n\u001b[0;32m     24\u001b[0m \u001b[0mcallbacks_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1103\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1105\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1106\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    452\u001b[0m     \"\"\"\n\u001b[0;32m    453\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    294\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unrecognized hook: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    354\u001b[0m       \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_supports_tf_logs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m         \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Only convert once.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1018\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1019\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1020\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1021\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1022\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m       \u001b[1;31m# Only block async when verbose = 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1084\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1085\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1086\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    512\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 514\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 659\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 659\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    508\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 510\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    511\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1069\u001b[0m     \"\"\"\n\u001b[0;32m   1070\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1071\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1072\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1073\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1035\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1037\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1038\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(\n",
    "    256,\n",
    "    input_shape=(X_train.shape[1], X_train.shape[2]),\n",
    "    return_sequences=True\n",
    "))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dense(256))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(VOCAB_SIZE+1))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "filepath = \"../weights/weights-{epoch:02d}-{loss:.4f}-bigger.hdf5\"    \n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath, monitor='loss', \n",
    "    verbose=0,        \n",
    "    save_best_only=True,        \n",
    "    mode='min'\n",
    ")    \n",
    "callbacks_list = [checkpoint]     \n",
    "model.fit(X_train, y_train, epochs=200, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"LSTM256.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('LSTM256.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(\n",
    "    256,\n",
    "    input_shape=(X_train.shape[1], X_train.shape[2]),\n",
    "    return_sequences=True\n",
    "))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dense(256))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(VOCAB_SIZE+1))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "# Load the weights to each node\n",
    "model.load_weights('../weights/weights-178-0.9515-bigger.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = np.random.randint(0, len(X)-1)\n",
    "intToNote = dict(map(reversed, tokenizer.word_index.items()))\n",
    "\n",
    "nrOfSong = 47\n",
    "\n",
    "pattern = midiTokensAsInt[nrOfSong][:100]\n",
    "#pattern = [i for [i] in pattern]\n",
    "prediction_output = []\n",
    "for tokenInt in pattern:\n",
    "    prediction_output.append(intToNote[tokenInt])\n",
    "\n",
    "# generate 500 notes\n",
    "for note_index in range(500):\n",
    "    prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    prediction_input = prediction_input / float(VOCAB_SIZE)\n",
    "    \n",
    "    prediction = model.predict(prediction_input, verbose=0)\n",
    "    \n",
    "    index = np.argmax(prediction)\n",
    "    result = intToNote[index]\n",
    "    prediction_output.append(result)\n",
    "    \n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole song:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div id='midiPlayerDiv47462'></div>\n",
       "                <link rel=\"stylesheet\" href=\"//cuthbertLab.github.io/music21j/css/m21.css\"\n",
       "                    type=\"text/css\" />\n",
       "                <script>\n",
       "                require.config({\n",
       "                    paths: {'music21': '//cuthbertLab.github.io/music21j/src/music21'}\n",
       "                });\n",
       "                require(['music21'], function() {\n",
       "                               mp = new music21.miditools.MidiPlayer();\n",
       "                               mp.addPlayer('#midiPlayerDiv47462');\n",
       "                               mp.base64Load('data:audio/midi;base64,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');\n",
       "                        });\n",
       "                </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input to network:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div id='midiPlayerDiv47751'></div>\n",
       "                <link rel=\"stylesheet\" href=\"//cuthbertLab.github.io/music21j/css/m21.css\"\n",
       "                    type=\"text/css\" />\n",
       "                <script>\n",
       "                require.config({\n",
       "                    paths: {'music21': '//cuthbertLab.github.io/music21j/src/music21'}\n",
       "                });\n",
       "                require(['music21'], function() {\n",
       "                               mp = new music21.miditools.MidiPlayer();\n",
       "                               mp.addPlayer('#midiPlayerDiv47751');\n",
       "                               mp.base64Load('data:audio/midi;base64,TVRoZAAAAAYAAQACBABNVHJrAAAAFAD/UQMHoSAA/1gEBAIYCIgA/y8ATVRyawAAAT0A/wMAAOAAQIgAkExwAJAtcACQNHAAkDlwggCATAAAkEhwggCASAAAkEVwggCARQAAkEFwAJBIcACQTXCCAIBBAACASAAAgE0AAJBIcIIAgEgAAJBFcIIAgEUAAJBOcIIAgE4AAJBIcIIAgEgAAJBFcIIAgEUAAJBBcACQSHAAkE1wggCAQQAAgEgAAIBNAACQSHCCAIBIAACQRXCCAIBFAACQTHCCAIBMAACQSHCCAIBIAACQR3CCAIAtAACANAAAgDkAAIBHAACQSnCCAIBKAACQTHAAkC1wAJA0cACQOXCCAIBMAACQSHCCAIBIAACQRXCCAIAtAACANAAAgDkAAIBFAACQQXAAkEhwAJBNcIIAgEEAAIBIAACATQAAkEhwggCASAAAkEVwggCARQAAkE5wggCATgCIAP8vAA==');\n",
       "                        });\n",
       "                </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Whole song:\")\n",
    "text2midi(miditokens[nrOfSong]).show(\"midi\")\n",
    "print(\"Input to network:\")\n",
    "text2midi(miditokens[nrOfSong][:100]).show(\"midi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <div id='midiPlayerDiv49320'></div>\n",
       "                <link rel=\"stylesheet\" href=\"//cuthbertLab.github.io/music21j/css/m21.css\"\n",
       "                    type=\"text/css\" />\n",
       "                <script>\n",
       "                require.config({\n",
       "                    paths: {'music21': '//cuthbertLab.github.io/music21j/src/music21'}\n",
       "                });\n",
       "                require(['music21'], function() {\n",
       "                               mp = new music21.miditools.MidiPlayer();\n",
       "                               mp.addPlayer('#midiPlayerDiv49320');\n",
       "                               mp.base64Load('data:audio/midi;base64,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');\n",
       "                        });\n",
       "                </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(prediction_output)\n",
    "genmidistream = text2midi(prediction_output)\n",
    "genmidistream.show(\"midi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fp = genmidistream.write('midi', fp='wow.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import *\n",
    "\n",
    "def text2midi(tokens):\n",
    "    s = stream.Stream()\n",
    "    \n",
    "    currentVelocity = 0\n",
    "\n",
    "    currentOffset = 0\n",
    "    currentToken = 0\n",
    "\n",
    "    for token in tokens:\n",
    "\n",
    "        splitToken = token.split(\":\")\n",
    "\n",
    "        if token.startswith(\"tempo\"):\n",
    "            s.append(tempo.MetronomeMark(number=float(splitToken[1])))\n",
    "\n",
    "        if token.startswith(\"timesig\"):\n",
    "            s.append(meter.TimeSignature(splitToken[1]))\n",
    "            \n",
    "        if token.startswith(\"velocity\"):\n",
    "            currentVelocity = int(splitToken[1])\n",
    "\n",
    "        if token.startswith(\"note\") and not token.lower().endswith(\"off\"):\n",
    "            noteDuration = 0\n",
    "            noteName = splitToken[1]\n",
    "\n",
    "            for element in tokens[currentToken+1:]:\n",
    "                splitToken2 = element.split(\":\")\n",
    "                if (element.startswith(\"wait\")):\n",
    "                    noteDuration += float(splitToken2[1])\n",
    "                if (element.startswith(\"note\") and element.lower().endswith(\"off\")):\n",
    "                    if (noteName == splitToken2[1]):\n",
    "                        newNote = note.Note(nameWithOctave=splitToken[1],  \n",
    "                               quarterLength=float(noteDuration))\n",
    "                        newNote.volume.velocity = currentVelocity\n",
    "                        s.insert(currentOffset, newNote)\n",
    "                        break\n",
    "\n",
    "        if token.startswith(\"wait\"):\n",
    "            currentOffset += float(splitToken[1]) \n",
    "\n",
    "        currentToken += 1\n",
    "\n",
    "    return s\n",
    "\n",
    "#text2midi(midiTokens).show(\"midi\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
