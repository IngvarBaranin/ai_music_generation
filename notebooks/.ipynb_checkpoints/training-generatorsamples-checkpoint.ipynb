{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional, Input, GlobalMaxPool1D, Activation\n",
    "from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of songs: 550\n"
     ]
    }
   ],
   "source": [
    "filename = '../dataset_text/miditokens_waitFix.txt'\n",
    "with open(filename) as f:\n",
    "    miditokens = f.readlines()\n",
    "    \n",
    "miditokens_tempo_and_sig = [tokens.strip().split(' ') for tokens in miditokens]\n",
    "\n",
    "miditokens = []\n",
    "for song in miditokens_tempo_and_sig:\n",
    "    sig = song[2]\n",
    "    if sig in ['timesig:4/4', 'timesig:3/4', 'timesig:2/4', 'timesig:6/8']:\n",
    "        miditokens.append(song)\n",
    "print(\"Number of songs: {0}\".format(len(miditokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(oov_token='x') # token -> int\n",
    "tokenizer.fit_on_texts(miditokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310\n"
     ]
    }
   ],
   "source": [
    "#sample = miditokens[1]\n",
    "#print(sample)\n",
    "#print(tokenizer.texts_to_sequences([sample])[0]) # Example of token input -> int output\n",
    "#print(\"Sõna sagedus kogu andmestikus\", tokenizer.word_counts['wait:0.0'])\n",
    "#print(\"Sõna -> indeks teisendus\", tokenizer.word_index['wait:0.0'])\n",
    "#print(\"Indeks -> sõna teisendus\", tokenizer.index_word[55])\n",
    "print(len(tokenizer.word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn all tokens to ints\n",
    "midiTokensAsInt = tokenizer.texts_to_sequences(miditokens)\n",
    "#midiTokensAsInt = np.array(midiTokensAsInt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 50\n",
    "\n",
    "with open(\"../dataset_text/seq2note_int.txt\", \"a\") as f:\n",
    "    for song in midiTokensAsInt:\n",
    "        for i in range(0, len(song) - SEQ_LEN, 1):\n",
    "            song = [str(token) for token in song]\n",
    "            f.write(' '.join(song[i:i + SEQ_LEN]) + \", \" + (song[i + SEQ_LEN]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357582\n"
     ]
    }
   ],
   "source": [
    "# https://medium.com/analytics-vidhya/train-keras-model-with-large-dataset-batch-training-6b3099fdf366\n",
    "\n",
    "LINES = 0\n",
    "for song in midiTokensAsInt:\n",
    "    for idx in range(0, len(song) - SEQ_LEN, 1):\n",
    "        LINES += 1\n",
    "print(LINES)\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "SEQ_LEN = 50\n",
    "VOCAB_SIZE = len(tokenizer.word_index)\n",
    "steps = LINES // BATCH_SIZE\n",
    "\n",
    "with open(\"../dataset_text/seq2note_int.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "def batchGenerator(trainData, lines, steps, VOCAB_SIZE, LINES, SEQ_LEN=50, BATCH_SIZE=32):\n",
    "    lastLine = 0\n",
    "    while True:\n",
    "        \n",
    "        # https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5\n",
    "        \n",
    "        X_train = []\n",
    "        y_train = []\n",
    "        \n",
    "        for idx in range(lastLine, min(lastLine + BATCH_SIZE, LINES), 1):\n",
    "            sample = lines[idx].split(\", \")\n",
    "            X_train.append([int(i) for i in sample[0].split(\" \")])\n",
    "            y_train.append(int(sample[1]))\n",
    "\n",
    "        X_train = to_categorical(X_train, num_classes=VOCAB_SIZE+1)\n",
    "        y_train = to_categorical(y_train, num_classes=VOCAB_SIZE+1)\n",
    "        \n",
    "        yield (X_train, y_train)\n",
    "        \n",
    "        lastLine += BATCH_SIZE\n",
    "        if lastLine > LINES:\n",
    "            lastLine = 0\n",
    "\n",
    "batchGen = batchGenerator(midiTokensAsInt, lines, steps, VOCAB_SIZE, LINES, SEQ_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = next(batchGen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2651/2651 [==============================] - 392s 148ms/step - loss: 0.8305\n",
      "Epoch 2/200\n",
      "2651/2651 [==============================] - 392s 148ms/step - loss: 0.8297\n",
      "Epoch 3/200\n",
      "2651/2651 [==============================] - 393s 148ms/step - loss: 0.8276\n",
      "Epoch 4/200\n",
      "2651/2651 [==============================] - 393s 148ms/step - loss: 0.8261\n",
      "Epoch 5/200\n",
      "2651/2651 [==============================] - 391s 147ms/step - loss: 0.8255\n",
      "Epoch 6/200\n",
      "2651/2651 [==============================] - 392s 148ms/step - loss: 0.8254\n",
      "Epoch 7/200\n",
      "2651/2651 [==============================] - 391s 148ms/step - loss: 0.8240\n",
      "Epoch 8/200\n",
      "2651/2651 [==============================] - 392s 148ms/step - loss: 0.8231\n",
      "Epoch 9/200\n",
      "2651/2651 [==============================] - 393s 148ms/step - loss: 0.8211\n",
      "Epoch 10/200\n",
      "2651/2651 [==============================] - 391s 148ms/step - loss: 0.8219\n",
      "Epoch 11/200\n",
      "2651/2651 [==============================] - 393s 148ms/step - loss: 0.8192\n",
      "Epoch 12/200\n",
      "2651/2651 [==============================] - 391s 148ms/step - loss: 0.8188\n",
      "Epoch 13/200\n",
      "2651/2651 [==============================] - 394s 149ms/step - loss: 0.8183\n",
      "Epoch 14/200\n",
      "2651/2651 [==============================] - 393s 148ms/step - loss: 0.8162\n",
      "Epoch 15/200\n",
      "2651/2651 [==============================] - 392s 148ms/step - loss: 0.8145\n",
      "Epoch 16/200\n",
      "2651/2651 [==============================] - 393s 148ms/step - loss: 0.8134\n",
      "Epoch 17/200\n",
      " 812/2651 [========>.....................] - ETA: 4:31 - loss: 0.7541"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-728-be2608a22709>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m           \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m           verbose=1)\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1103\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1105\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1106\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    452\u001b[0m     \"\"\"\n\u001b[0;32m    453\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    294\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unrecognized hook: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    354\u001b[0m       \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_supports_tf_logs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m         \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Only convert once.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1018\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1019\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1020\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1021\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1022\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m       \u001b[1;31m# Only block async when verbose = 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1084\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1085\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1086\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    512\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 514\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 659\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 659\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    508\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 510\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    511\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1069\u001b[0m     \"\"\"\n\u001b[0;32m   1070\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1071\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1072\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1073\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1035\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1037\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1038\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#model = Sequential()\n",
    "#model.add(LSTM(\n",
    "#    256,\n",
    "#    input_shape=(SEQ_LEN, VOCAB_SIZE+1),\n",
    "#    return_sequences=True\n",
    "#))\n",
    "#model.add(Dropout(0.3))\n",
    "#model.add(LSTM(256, return_sequences=True))\n",
    "#model.add(Dropout(0.3))\n",
    "#model.add(LSTM(256))\n",
    "#model.add(Dense(256))\n",
    "#model.add(Dropout(0.3))\n",
    "#model.add(Dense(VOCAB_SIZE+1))\n",
    "#model.add(Activation('softmax'))\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "#\n",
    "#filepath = \"../weights/weights-generator/weights-{epoch:02d}-{loss:.4f}.hdf5\"    \n",
    "#checkpoint = ModelCheckpoint(\n",
    "#    filepath, monitor='loss', \n",
    "#    verbose=0,        \n",
    "#    save_best_only=True,        \n",
    "#    mode='min'\n",
    "#)    \n",
    "#callbacks_list = [checkpoint]     \n",
    "##model.fit(network_input, network_output, epochs=200, batch_size=64, callbacks=callbacks_list)\n",
    "\n",
    "model.fit(batchGen, \n",
    "          workers=0,\n",
    "          steps_per_epoch = steps,\n",
    "          epochs=200,\n",
    "          callbacks=callbacks_list,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"LSTM256-generator2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"../trained_models/LSTM256-generator2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Sequential()\n",
    "#model.add(LSTM(\n",
    "#    256,\n",
    "#    input_shape=(X_train.shape[1], X_train.shape[2]),\n",
    "#    return_sequences=True\n",
    "#))\n",
    "#model.add(Dropout(0.3))\n",
    "#model.add(LSTM(256, return_sequences=True))\n",
    "#model.add(Dropout(0.3))\n",
    "#model.add(LSTM(256))\n",
    "#model.add(Dense(256))\n",
    "#model.add(Dropout(0.3))\n",
    "#model.add(Dense(VOCAB_SIZE))\n",
    "#model.add(Activation('softmax'))\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "#\n",
    "## Load the weights to each node\n",
    "#model.load_weights('../weights/weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <div id='midiPlayerDiv208545'></div>\n",
       "                <link rel=\"stylesheet\" href=\"//cuthbertLab.github.io/music21j/css/m21.css\"\n",
       "                    type=\"text/css\" />\n",
       "                <script>\n",
       "                require.config({\n",
       "                    paths: {'music21': '//cuthbertLab.github.io/music21j/src/music21'}\n",
       "                });\n",
       "                require(['music21'], function() {\n",
       "                               mp = new music21.miditools.MidiPlayer();\n",
       "                               mp.addPlayer('#midiPlayerDiv208545');\n",
       "                               mp.base64Load('data:audio/midi;base64,TVRoZAAAAAYAAQACBABNVHJrAAAAFAD/UQMFYq0A/1gEBAIYCIgA/y8ATVRyawAAAIgA/wMAAOAAQIgAkFFAggCQTUBVgFEAgSuATQAAkFFAAJAhQIIAgFEAAJBNQIIAgCEAAIBNAACQU0AAkC1QggCAUwAAkE9AggCALQAAgE8AAJBTQACQIUCCAIBTAACQT0CCAIAhAACATwAAkFRAAJAiUIIAgFQAAJBRQIIAgCIAAIBRAIgA/y8A');\n",
       "                        });\n",
       "                </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['start', 'tempo:170.0', 'timesig:4/4', 'velocity:64', 'note:a5', 'wait:0.25', 'note:f5', 'wait:0.08333', 'note:a5:off', 'wait:0.16667', 'note:f5:off', 'note:a5', 'note:a1', 'wait:0.25', 'note:a5:off', 'note:f5', 'wait:0.25', 'note:a1:off', 'note:f5:off', 'note:b5', 'velocity:80', 'note:a2', 'wait:0.25', 'note:b5:off', 'velocity:64', 'note:g5', 'wait:0.25', 'note:a2:off', 'note:g5:off', 'note:b5', 'note:a1', 'wait:0.25', 'note:b5:off', 'note:g5', 'wait:0.25', 'note:a1:off', 'note:g5:off', 'note:c6', 'velocity:80', 'note:b-1', 'wait:0.25', 'note:c6:off', 'velocity:64', 'note:a5', 'wait:0.25', 'note:b-1:off', 'note:a5:off', 'note:c6', 'velocity:80', 'note:b-2', 'wait:0.25', 'note:c6:off', 'velocity:64', 'note:f6', 'wait:0.25', 'note:b-2:off', 'note:f6:off', 'note:c5', 'note:a1', 'wait:0.25', 'note:c5:off', 'velocity:80', 'note:d5', 'wait:0.25', 'note:a1:off', 'note:d5:off', 'note:e5', 'velocity:64', 'note:a1', 'wait:0.25', 'note:e5:off', 'velocity:80', 'note:f5', 'wait:0.25', 'note:a1:off', 'note:f5:off', 'note:g5', 'velocity:64', 'note:a1', 'wait:0.25', 'note:g5:off', 'velocity:80', 'note:f#5', 'wait:0.25', 'note:a1:off', 'note:f#5:off', 'note:e5', 'wait:0.5', 'note:e5:off', 'note:d5', 'velocity:64', 'note:b1', 'wait:0.25', 'note:b1:off', 'note:b1', 'wait:0.25', 'note:d5:off', 'note:b1:off', 'velocity:80', 'note:c5', 'velocity:64', 'note:b1', 'wait:0.25', 'note:c5:off', 'velocity:80', 'note:d5', 'wait:0.25', 'note:b1:off', 'note:d5:off', 'note:e5', 'velocity:64', 'note:b1', 'wait:0.25', 'note:e5:off', 'velocity:80', 'note:d5', 'wait:0.25', 'note:b1:off', 'note:d5:off', 'note:e5', 'note:b1', 'wait:0.5', 'note:e5:off', 'note:b1:off', 'velocity:64', 'note:d5', 'velocity:80', 'note:b1', 'wait:0.25', 'note:d5:off', 'velocity:64', 'note:c#5', 'wait:0.25', 'note:b1:off', 'note:c#5:off', 'velocity:80', 'note:d5', 'velocity:64', 'note:b1', 'wait:0.25', 'note:d5:off', 'velocity:80', 'note:d5', 'wait:0.25', 'note:b1:off', 'note:d5:off', 'velocity:64', 'note:e5', 'velocity:80', 'note:b1', 'wait:0.25', 'note:e5:off', 'velocity:64', 'note:d5', 'wait:0.25', 'note:b1:off', 'note:d5:off', 'note:e5', 'velocity:80', 'note:c2', 'wait:0.25', 'note:e5:off', 'velocity:64', 'note:d5', 'wait:0.25', 'note:c2:off', 'note:d5:off', 'note:e5', 'note:c2', 'wait:0.25', 'note:e5:off', 'note:c5', 'wait:0.25', 'note:c2:off', 'note:c5:off', 'note:d5', 'velocity:80', 'note:c2', 'wait:0.25', 'note:d5:off', 'velocity:64', 'note:e5', 'wait:0.25', 'note:c2:off', 'note:e5:off', 'velocity:80', 'note:e5', 'note:g2', 'wait:0.25', 'note:e5:off', 'note:c5', 'wait:0.25', 'note:g2:off', 'note:c5:off', 'note:b4', 'note:g2', 'wait:0.25', 'note:b4:off', 'note:c5', 'wait:0.25', 'note:g2:off', 'note:c5:off', 'note:b4', 'velocity:64', 'note:g2', 'wait:0.5', 'note:b4:off', 'note:g2:off', 'velocity:80', 'note:c5', 'velocity:64', 'note:g2', 'wait:0.5', 'note:g2:off', 'note:g2', 'wait:0.5', 'note:g2:off', 'velocity:80', 'note:g2', 'wait:0.5', 'note:g2:off', 'velocity:64', 'note:g2', 'wait:0.5', 'note:g2:off', 'velocity:80', 'note:g2', 'wait:0.5', 'note:g2:off', 'note:g2', 'wait:0.5', 'note:g2:off', 'note:g2', 'wait:0.5', 'note:g2:off', 'note:g2', 'wait:0.5', 'note:g2:off', 'note:g2', 'wait:0.5', 'note:g2:off', 'note:g2', 'wait:0.5', 'note:g2:off', 'note:d4', 'note:g2', 'wait:0.25', 'note:d4:off', 'note:d4', 'wait:0.25', 'note:g2:off', 'note:d4:off', 'note:d4', 'wait:0.5', 'note:d4:off', 'note:g4', 'wait:0.5', 'note:g4:off', 'note:f4', 'note:g2', 'wait:0.5', 'note:g2:off', 'note:g2', 'wait:0.5', 'note:g2:off', 'note:g2', 'wait:0.5', 'note:g2:off', 'note:g2', 'wait:0.5', 'note:f4:off', 'note:g2:off', 'note:e4', 'note:g2', 'wait:0.5', 'note:e4:off', 'note:g2:off', 'note:f4', 'note:g2', 'wait:0.5', 'note:f4:off', 'note:g2:off', 'note:e4', 'note:g2', 'wait:0.5', 'note:e4:off', 'note:g2:off', 'note:d4', 'note:g2', 'wait:0.5', 'note:d4:off', 'note:g2:off', 'note:e4', 'note:g2', 'wait:0.5', 'note:e4:off', 'note:g2:off', 'note:d4', 'note:g2', 'wait:0.5', 'note:d4:off', 'note:g2:off', 'note:e4', 'note:g2', 'wait:0.5', 'note:e4:off', 'note:g2:off', 'note:e4', 'note:g2', 'wait:0.5', 'note:e4:off', 'note:g2:off', 'note:d4', 'note:g2', 'wait:0.5', 'note:d4:off', 'note:g2:off', 'note:e4', 'note:g2', 'wait:0.5', 'note:e4:off', 'note:g2:off', 'note:d4', 'note:g2', 'wait:0.5', 'note:d4:off', 'note:g2:off', 'note:e4', 'note:g2', 'wait:0.5', 'note:e4:off', 'note:g2:off', 'note:d4', 'note:g2', 'wait:0.5', 'note:d4:off', 'note:g2:off', 'note:e4', 'note:g2', 'wait:0.5', 'note:e4:off', 'note:g2:off', 'note:d4', 'note:g2', 'wait:0.5', 'note:d4:off', 'note:g2:off', 'note:e4', 'note:g2', 'wait:0.5', 'note:e4:off', 'note:g2:off', 'note:d4', 'note:g2', 'wait:0.5', 'note:d4:off', 'note:g2:off', 'note:e4', 'note:g2', 'wait:0.5', 'note:e4:off', 'note:g2:off', 'note:d4', 'note:g2', 'wait:0.5', 'note:d4:off', 'note:g2:off', 'note:e4', 'note:g2', 'wait:0.5', 'note:e4:off', 'note:g2:off', 'note:d4', 'note:g2', 'wait:0.5', 'note:d4:off', 'note:g2:off', 'note:e4', 'note:g2', 'wait:0.5', 'note:e4:off', 'note:g2:off', 'note:d4', 'note:g2', 'wait:0.5', 'note:d4:off', 'note:g2:off', 'note:e4', 'note:g2', 'wait:0.5', 'note:e4:off', 'note:g2:off', 'note:d4', 'note:g2', 'wait:0.5', 'note:d4:off', 'note:g2:off', 'note:e4', 'note:g2', 'wait:0.5', 'note:e4:off', 'note:g2:off', 'note:d4', 'note:g2', 'wait:0.5', 'note:d4:off', 'note:g2:off', 'note:e4', 'note:g2', 'wait:0.5', 'note:e4:off', 'note:g2:off', 'note:d4', 'note:g2', 'wait:0.5', 'note:d4:off', 'note:g2:off', 'note:e4', 'note:g2', 'wait:0.5', 'note:e4:off', 'note:g2:off', 'note:d4', 'note:g2', 'wait:0.5', 'note:d4:off', 'note:g2:off', 'note:e4', 'note:g2', 'wait:0.5', 'note:e4:off', 'note:g2:off', 'note:d4', 'note:g2', 'wait:0.5', 'note:d4:off', 'note:g2:off', 'note:e4', 'note:g2', 'wait:0.5', 'note:e4:off', 'note:g2:off', 'note:d4', 'note:g2', 'wait:0.5', 'note:d4:off', 'note:g2:off', 'note:e4', 'note:g2', 'wait:0.5', 'note:e4:off', 'note:g2:off', 'note:d4', 'note:g2', 'wait:0.5', 'note:d4:off', 'note:g2:off', 'note:e4', 'note:g2', 'wait:0.5', 'note:e4:off', 'note:g2:off', 'note:d4', 'note:g2', 'wait:0.5', 'note:d4:off', 'note:g2:off', 'note:e4', 'note:g2', 'wait:0.5', 'note:e4:off', 'note:g2:off', 'note:d4', 'note:g2', 'wait:0.5', 'note:d4:off', 'note:g2:off', 'note:e4', 'note:g2', 'wait:0.5', 'note:e4:off', 'note:g2:off', 'note:d4', 'note:g2', 'wait:0.5', 'note:d4:off', 'note:g2:off', 'note:e4', 'note:g2', 'wait:0.5', 'note:e4:off', 'note:g2:off', 'note:d4', 'note:g2', 'wait:0.5', 'note:d4:off', 'note:g2:off', 'note:e4', 'note:g2', 'wait:0.5', 'note:e4:off', 'note:g2:off', 'note:d4', 'note:g2', 'wait:0.5', 'note:d4:off', 'note:g2:off', 'note:e4', 'note:g2', 'wait:0.5', 'note:e4:off', 'note:g2:off', 'note:d4', 'note:g2', 'wait:0.5', 'note:d4:off', 'note:g2:off', 'note:e4', 'note:g2', 'wait:0.5', 'note:e4:off', 'note:g2:off', 'note:d4', 'note:g2', 'wait:0.5', 'note:d4:off', 'note:g2:off', 'note:e4', 'note:g2', 'wait:0.5', 'note:e4:off', 'note:g2:off', 'note:d4', 'note:g2', 'wait:0.5', 'note:d4:off', 'note:g2:off', 'note:e4', 'note:g2', 'wait:0.5', 'note:e4:off', 'note:g2:off', 'note:d4', 'note:g2', 'wait:0.5', 'note:d4:off', 'note:g2:off', 'note:e4', 'note:g2', 'wait:0.5']\n"
     ]
    }
   ],
   "source": [
    "intToNote = dict(map(reversed, tokenizer.word_index.items()))\n",
    "\n",
    "songTokens = tokenizer.texts_to_sequences([midi2text(open_midi(\"../testmidis/sonic.mid\"))])[0]\n",
    "pattern = [songTokens[:50]] \n",
    "\n",
    "prediction_output = [intToNote[i] for i in list(pattern[0])] # The starting input will be the beginning of the output \n",
    "\n",
    "starting_input = text2midi(prediction_output)\n",
    "starting_input.show(\"midi\")\n",
    "starting_input.write('midi', fp='../results/sonic_input.mid')\n",
    "\n",
    "# Range determines the number of tokens to predict\n",
    "for note_index in range(500):\n",
    "    # Convert to acceptable format for trained model\n",
    "    prediction_input = to_categorical(pattern, num_classes=VOCAB_SIZE+1)\n",
    "    \n",
    "    # Predict next token depending on the previous 50 tokens\n",
    "    prediction = model.predict(prediction_input, verbose=0)\n",
    "    index = np.argmax(prediction)\n",
    "    result = intToNote[index]\n",
    "    \n",
    "    prediction_output.append(result)\n",
    "    \n",
    "    pattern = np.append(pattern, index)\n",
    "    pattern = [pattern[1:len(pattern)]]\n",
    "    \n",
    "print(prediction_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <div id='midiPlayerDiv210652'></div>\n",
       "                <link rel=\"stylesheet\" href=\"//cuthbertLab.github.io/music21j/css/m21.css\"\n",
       "                    type=\"text/css\" />\n",
       "                <script>\n",
       "                require.config({\n",
       "                    paths: {'music21': '//cuthbertLab.github.io/music21j/src/music21'}\n",
       "                });\n",
       "                require(['music21'], function() {\n",
       "                               mp = new music21.miditools.MidiPlayer();\n",
       "                               mp.addPlayer('#midiPlayerDiv210652');\n",
       "                               mp.base64Load('data:audio/midi;base64,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');\n",
       "                        });\n",
       "                </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'../results/sonic_output.mid'"
      ]
     },
     "execution_count": 751,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genmidistream = text2midi(prediction_output)\n",
    "genmidistream.show(\"midi\")\n",
    "genmidistream.write('midi', fp='../results/sonic_output.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import *\n",
    "\n",
    "def open_midi(midi_path):\n",
    "    mf = converter.parse(midi_path)\n",
    "    return mf\n",
    "\n",
    "# Restricts possible velocities to 8 values, keeping the number of unique note events smaller\n",
    "# Resembles ppp, pp, p, mp, mf, f, ff, fff dynamics \n",
    "def vModifier(velocity):\n",
    "    if (velocity == 0):\n",
    "        return 0\n",
    "    \n",
    "    velocity = min(127, ((velocity // 16) + 1) * 16)\n",
    "    return velocity\n",
    "\n",
    "def tModifier(tempo):\n",
    "    if (tempo == 0):\n",
    "        return 0\n",
    "    \n",
    "    tempo = ((tempo // 10) + 1) * 10\n",
    "    return tempo\n",
    "\n",
    "# Check if there are notes which should have ended before given offset\n",
    "def checkForNoteOffEvent(currentOffset, noteOffEvents):\n",
    "    notesToEnd = []\n",
    "    \n",
    "    for noteOffEvent in noteOffEvents: # for (notename, endingOffset)\n",
    "        if noteOffEvent[1] <= currentOffset:\n",
    "            notesToEnd.append(noteOffEvent)\n",
    "            \n",
    "    return notesToEnd\n",
    "\n",
    "def midi2text(midifile):\n",
    "    previousElementOffset = 0.0\n",
    "    offsetChanged = False\n",
    "\n",
    "    tempoRetrieved = False\n",
    "    timeSigRetrieved = False\n",
    "    \n",
    "    currentVelocity = 0\n",
    "\n",
    "    tokens = []\n",
    "    noteOffEvents = []\n",
    "\n",
    "    tokens.append(\"START\")\n",
    "\n",
    "    for element in midifile.flat.elements:\n",
    "        #print(type(element))\n",
    "\n",
    "        currentElementOffset = element.offset\n",
    "\n",
    "        notesToEnd = checkForNoteOffEvent(currentElementOffset, noteOffEvents)\n",
    "\n",
    "        if (len(notesToEnd) != 0):\n",
    "            for noteToEnd in notesToEnd:\n",
    "                difference = float(noteToEnd[1]) - float(previousElementOffset)\n",
    "                if (difference > 0.01):\n",
    "                    tokens.append(\"wait:\" + str(round(difference, 5)))\n",
    "                    previousElementOffset = noteToEnd[1]\n",
    "                tokens.append(\"note:\" + str(noteToEnd[0]) + \":OFF\")\n",
    "                noteOffEvents.remove(noteToEnd)\n",
    "\n",
    "        # If offset has increased and we're looking at new notes, add a wait event before adding the new notes\n",
    "        if (float(currentElementOffset) > float(previousElementOffset + 0.01) and (isinstance(element, note.Note) or isinstance(element, chord.Chord))):\n",
    "            offsetChanged = True\n",
    "            difference = float(currentElementOffset - previousElementOffset)\n",
    "            tokens.append(\"wait:\" + str(round(difference, 5)))\n",
    "\n",
    "        if (isinstance(element, tempo.MetronomeMark) and not tempoRetrieved):\n",
    "            tempoRetrieved = True\n",
    "            tokens.append(\"tempo:\" + str(tModifier(element.number)))\n",
    "\n",
    "        if (isinstance(element, meter.TimeSignature) and not timeSigRetrieved):\n",
    "            timeSigRetrieved = True\n",
    "            tokens.append(\"timesig:\" + str(element.ratioString))\n",
    "\n",
    "        if (isinstance(element, note.Note)): # This is a note event, add a token for this note\n",
    "            if (currentVelocity != vModifier(element.volume.velocity)):\n",
    "                currentVelocity = vModifier(element.volume.velocity)\n",
    "                tokens.append(\"velocity:\" + str(currentVelocity))\n",
    "            tokens.append(\"note:\" + str(element.pitch))\n",
    "            noteOffEvents.append((str(element.pitch), float(currentElementOffset + element.duration.quarterLength), 5))\n",
    "\n",
    "        if (isinstance(element, chord.Chord)): # This is a chord event, add a token for each note in chord\n",
    "            for chordnote in element:\n",
    "                if (currentVelocity != vModifier(element.volume.velocity)):\n",
    "                    currentVelocity = vModifier(element.volume.velocity)\n",
    "                    tokens.append(\"velocity:\" + str(currentVelocity))\n",
    "                tokens.append(\"note:\" + str(chordnote.pitch))\n",
    "                noteOffEvents.append((str(chordnote.pitch), float(currentElementOffset + element.duration.quarterLength)))\n",
    "\n",
    "        if (offsetChanged):\n",
    "            previousElementOffset = currentElementOffset\n",
    "            offsetChanged = False\n",
    "\n",
    "    # Finally make sure that all notes that end after the offset of the last element of mf.flat.elements are given an off event.\n",
    "    for noteToEnd in noteOffEvents.copy():\n",
    "        difference = float(noteToEnd[1]) - float(previousElementOffset)\n",
    "        if (difference > 0.01):\n",
    "            tokens.append(\"wait:\" + str(round(difference, 5)))\n",
    "            previousElementOffset = noteToEnd[1]\n",
    "        tokens.append(\"note:\" + str(noteToEnd[0]) + \":OFF\")\n",
    "        noteOffEvents.remove(noteToEnd)\n",
    "        \n",
    "    if (len(noteOffEvents) != 0):\n",
    "        print(\"Not all notes have note-off events\")\n",
    "\n",
    "    tokens.append(\"END\")\n",
    "    return tokens\n",
    "\n",
    "def text2midi(tokens):\n",
    "    s = stream.Stream()\n",
    "    \n",
    "    currentVelocity = 80\n",
    "\n",
    "    currentOffset = 0\n",
    "    currentToken = 0\n",
    "\n",
    "    for token in tokens:\n",
    "\n",
    "        splitToken = token.split(\":\")\n",
    "\n",
    "        if token.startswith(\"tempo\"):\n",
    "            s.append(tempo.MetronomeMark(number=float(splitToken[1])))\n",
    "\n",
    "        if token.startswith(\"timesig\"):\n",
    "            s.append(meter.TimeSignature(splitToken[1]))\n",
    "            \n",
    "        if token.startswith(\"velocity\"):\n",
    "            currentVelocity = int(splitToken[1])\n",
    "\n",
    "        if token.startswith(\"note\") and not token.lower().endswith(\"off\"):\n",
    "            noteDuration = 0\n",
    "            noteName = splitToken[1]\n",
    "\n",
    "            for element in tokens[currentToken+1:]:\n",
    "                splitToken2 = element.split(\":\")\n",
    "                if (element.startswith(\"wait\")):\n",
    "                    noteDuration += float(splitToken2[1])\n",
    "                if (element.startswith(\"note\") and element.lower().endswith(\"off\")):\n",
    "                    if (noteName == splitToken2[1]):\n",
    "                        newNote = note.Note(nameWithOctave=splitToken[1],  \n",
    "                               quarterLength=float(noteDuration))\n",
    "                        newNote.volume.velocity = currentVelocity\n",
    "                        s.insert(currentOffset, newNote)\n",
    "                        break\n",
    "\n",
    "        if token.startswith(\"wait\"):\n",
    "            currentOffset += float(splitToken[1]) \n",
    "\n",
    "        currentToken += 1\n",
    "\n",
    "    return s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
