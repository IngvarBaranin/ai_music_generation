{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional, Input, GlobalMaxPool1D, Activation\n",
    "from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "%run midi2text2midi.ipynb\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data\n",
    "\n",
    "#### Keep timesigs 4/4, 3/4, 2/4, 6/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of songs: 550\n"
     ]
    }
   ],
   "source": [
    "filename = '../dataset_text/miditokens_waitFix.txt'\n",
    "with open(filename) as f:\n",
    "    miditokens = f.readlines()\n",
    "    \n",
    "miditokens_tempo_and_sig = [tokens.strip().split(' ') for tokens in miditokens]\n",
    "\n",
    "miditokens = []\n",
    "for song in miditokens_tempo_and_sig:\n",
    "    sig = song[2]\n",
    "    if sig in ['timesig:4/4', 'timesig:3/4', 'timesig:2/4', 'timesig:6/8']:\n",
    "        miditokens.append(song)\n",
    "print(\"Number of songs: {0}\".format(len(miditokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 310\n",
      "13854\n",
      "27\n",
      "wait:1.0\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(oov_token='x') # token -> int\n",
    "tokenizer.fit_on_texts(miditokens)\n",
    "\n",
    "print(\"Number of unique tokens: {0}\".format(len(tokenizer.word_index)))\n",
    "\n",
    "# Example of token input -> int output\n",
    "# sample = miditokens[0]\n",
    "# print(tokenizer.texts_to_sequences([sample])[0]) \n",
    "\n",
    "# Get count of word in whole dataset\n",
    "print(tokenizer.word_counts['wait:1.0'])\n",
    "\n",
    "# Get class index of a token \n",
    "print(tokenizer.word_index['wait:1.0'])\n",
    "\n",
    "# Get token of a class index\n",
    "print(tokenizer.index_word[27])\n",
    "\n",
    "\n",
    "# Turn all tokens to ints\n",
    "midiTokensAsInt = tokenizer.texts_to_sequences(miditokens)\n",
    "\n",
    "# Get inverse map of tokenizer\n",
    "intToNote = dict(map(reversed, tokenizer.word_index.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 50\n",
    "pathToOutput = \"../dataset_text/seq2note_int.txt\"\n",
    "\n",
    "def writeGeneratorLinesToFile(pathToOutputFile):\n",
    "    with open(pathToOutputFile, \"a\") as f:\n",
    "        for song in midiTokensAsInt:\n",
    "            for i in range(0, len(song) - SEQ_LEN, 1):\n",
    "                song = [str(token) for token in song]\n",
    "                f.write(' '.join(song[i:i + SEQ_LEN]) + \", \" + (song[i + SEQ_LEN]) + '\\n')\n",
    "                \n",
    "def getNumberOfLinesInGeneratorFile():\n",
    "    LINES = 0\n",
    "    for song in midiTokensAsInt:\n",
    "        for idx in range(0, len(song) - SEQ_LEN, 1):\n",
    "            LINES += 1\n",
    "    return LINES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/analytics-vidhya/train-keras-model-with-large-dataset-batch-training-6b3099fdf366\n",
    "\n",
    "LINES = getNumberOfLinesInGeneratorFile()\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "VOCAB_SIZE = len(tokenizer.word_index)\n",
    "steps = LINES // BATCH_SIZE\n",
    "\n",
    "with open(\"../dataset_text/seq2note_int.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "def batchGenerator(trainData, lines, steps, VOCAB_SIZE, LINES, SEQ_LEN=50, BATCH_SIZE=32):\n",
    "    lastLine = 0\n",
    "    while True:\n",
    "        \n",
    "        # https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5\n",
    "        \n",
    "        X_train = []\n",
    "        y_train = []\n",
    "        \n",
    "        for idx in range(lastLine, min(lastLine + BATCH_SIZE, LINES), 1):\n",
    "            sample = lines[idx].split(\", \")\n",
    "            X_train.append([int(i) for i in sample[0].split(\" \")])\n",
    "            y_train.append(int(sample[1]))\n",
    "\n",
    "        X_train = to_categorical(X_train, num_classes=VOCAB_SIZE+1)\n",
    "        y_train = to_categorical(y_train, num_classes=VOCAB_SIZE+1)\n",
    "        \n",
    "        yield (X_train, y_train)\n",
    "        \n",
    "        lastLine += BATCH_SIZE\n",
    "        if lastLine > LINES:\n",
    "            lastLine = 0\n",
    "\n",
    "batchGen = batchGenerator(midiTokensAsInt, lines, steps, VOCAB_SIZE, LINES, SEQ_LEN, BATCH_SIZE)\n",
    "#test = next(batchGen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Sequential()\n",
    "#model.add(LSTM(\n",
    "#    256,\n",
    "#    input_shape=(SEQ_LEN, VOCAB_SIZE+1),\n",
    "#    return_sequences=True\n",
    "#))\n",
    "#model.add(Dropout(0.3))\n",
    "#model.add(LSTM(256, return_sequences=True))\n",
    "#model.add(Dropout(0.3))\n",
    "#model.add(LSTM(256))\n",
    "#model.add(Dense(256))\n",
    "#model.add(Dropout(0.3))\n",
    "#model.add(Dense(VOCAB_SIZE+1))\n",
    "#model.add(Activation('softmax'))\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "#\n",
    "#filepath = \"../weights/weights-generator/weights-{epoch:02d}-{loss:.4f}.hdf5\"    \n",
    "#checkpoint = ModelCheckpoint(\n",
    "#    filepath, monitor='loss', \n",
    "#    verbose=0,        \n",
    "#    save_best_only=True,        \n",
    "#    mode='min'\n",
    "#)    \n",
    "#callbacks_list = [checkpoint]     \n",
    "##model.fit(network_input, network_output, epochs=200, batch_size=64, callbacks=callbacks_list)\n",
    "\n",
    "model.fit(batchGen, \n",
    "          workers=0,\n",
    "          steps_per_epoch = steps,\n",
    "          epochs=200,\n",
    "          callbacks=callbacks_list,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('../trained_models/' + str(input()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"../trained_models/LSTM256-generator2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to generate subsequent tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printLoading(tokensGenerated, toGenerate, generateUntilEnd):\n",
    "    clear_output(wait=True)\n",
    "    if (not generateUntilEnd):\n",
    "        print(\"{0} / {1} generated\".format(tokensGenerated, toGenerate))\n",
    "        return\n",
    "    print(\"{0} / {1} generated\".format(tokensGenerated, \"?\"))\n",
    "\n",
    "def generateSubsequentTokens(model, toGenerate = 500, startingInput = [], generateUntilEnd = False):\n",
    "    # Range determines the number of tokens to predict\n",
    "    \n",
    "    keepGenerating = True\n",
    "    tokensGenerated = 0\n",
    "    \n",
    "    slidingSequence = [startingInput.copy()]\n",
    "    predictionOutput = [intToNote[i] for i in startingInput.copy()]\n",
    "    \n",
    "    while keepGenerating:\n",
    "        # Convert to acceptable format for trained model\n",
    "        prediction_input = to_categorical(slidingSequence, num_classes=VOCAB_SIZE+1)\n",
    "\n",
    "        # Predict next token depending on the previous 50 tokens\n",
    "        prediction = model.predict(prediction_input, verbose=0)\n",
    "        index = np.argmax(prediction)\n",
    "\n",
    "        # Check if previous tokens were \"varied\" enough, if not, choose a random prediction from the top 3 predictions\n",
    "        if (len(np.unique(slidingSequence)) < 15):\n",
    "            ind = np.argpartition(prediction[0], -3)[-3:]\n",
    "            index = np.random.choice(ind)\n",
    "\n",
    "        result = intToNote[index]\n",
    "\n",
    "        predictionOutput.append(result)\n",
    "        tokensGenerated += 1\n",
    "\n",
    "        slidingSequence = np.append(slidingSequence, index)\n",
    "        slidingSequence = [slidingSequence[1:len(slidingSequence)]]\n",
    "        \n",
    "        printLoading(tokensGenerated, toGenerate, generateUntilEnd)\n",
    "        \n",
    "        if (generateUntilEnd and result == \"end\") or (not generateUntilEnd and tokensGenerated == toGenerate):\n",
    "            keepGenerating = False\n",
    "            \n",
    "    return predictionOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 / 500 generated\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div id='midiPlayerDiv22017'></div>\n",
       "                <link rel=\"stylesheet\" href=\"//cuthbertLab.github.io/music21j/css/m21.css\"\n",
       "                    type=\"text/css\" />\n",
       "                <script>\n",
       "                require.config({\n",
       "                    paths: {'music21': '//cuthbertLab.github.io/music21j/src/music21'}\n",
       "                });\n",
       "                require(['music21'], function() {\n",
       "                               mp = new music21.miditools.MidiPlayer();\n",
       "                               mp.addPlayer('#midiPlayerDiv22017');\n",
       "                               mp.base64Load('data:audio/midi;base64,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');\n",
       "                        });\n",
       "                </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "songTokens = tokenizer.texts_to_sequences([midi2text(open_midi(\"../testmidis/supermario.mid\"))])[0][:50]\n",
    "generatedTokens = generateSubsequentTokens(model, startingInput = songTokens, generateUntilEnd = False)\n",
    "genmidistream = text2midi(generatedTokens)\n",
    "genmidistream.show(\"midi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genmidistream.write('midi', fp='../results/' + str(input()) + '.mid')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
